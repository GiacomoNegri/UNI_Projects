{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7afb88a7-49bc-4309-b8da-c0254a69c027",
   "metadata": {},
   "source": [
    "# Assignment II: 20597 - Natural Langauge Processing\n",
    "## Giacomo Negri, 3155287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bef65e-9166-4476-b8dd-d4fbae95670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "import gensim.downloader as api\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e50fbd-a6bf-4940-8c94-177fa300e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    dev_responses = pd.read_csv('dev_responses.csv')\n",
    "    train_responses = pd.read_csv('train_responses.csv')\n",
    "    return pd.concat([dev_responses, train_responses], ignore_index=True)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea50338-9582-4d0b-840c-1e2363005e2a",
   "metadata": {},
   "source": [
    "## Track I\n",
    "This code use TF-IDF vectorization and cosine similarity. After loading the data, they are lighly preprocessed, removing white spaces, punctuation and lowering capitalized words. Then it was employed a TfidfVectorizer from sklearn. Different n-gram ranges for words and characters were used and then the vectorizers were combined using FeatureUnion. The tuning of the parameters (ngram_range, max_df, min_df, sublinear_tf) was achived by triyng multiple combinations and selecting the most solid one aross different seeds with respect to the BLEU score. The model transforms the processed test prompts into TF-IDF vectors and computes cosine similarity to find the most relevant training prompt response for each test prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb15288-dd82-4525-a0a3-6fd305380121",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = load_data()\n",
    "test_prompts=pd.read_csv('test_prompts.csv')\n",
    "\n",
    "combined_data['user_prompt'] = combined_data['user_prompt'].astype(str)\n",
    "combined_data['model_response'] = combined_data['model_response'].astype(str)\n",
    "\n",
    "combined_data['processed_prompt'] = combined_data['user_prompt'].apply(preprocess_text)\n",
    "test_prompts['processed_prompt'] = test_prompts['user_prompt'].apply(preprocess_text)\n",
    "\n",
    "ngram_range_w = (1,2)\n",
    "ngram_range_c = (2,4)\n",
    "max_df = 0.80\n",
    "min_df = 1\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=ngram_range_w, max_df=max_df, min_df=min_df, analyzer='word', sublinear_tf=True)\n",
    "char_vectorizer = TfidfVectorizer(ngram_range=ngram_range_c, max_df=max_df, min_df=min_df, analyzer='char', sublinear_tf=True)\n",
    "vectorizer = FeatureUnion([(\"word_tfidf\", word_vectorizer), (\"char_tfidf\", char_vectorizer)])\n",
    "\n",
    "tfidf_train = vectorizer.fit_transform(combined_data['processed_prompt'])\n",
    "tfidf_test = vectorizer.transform(test_prompts['processed_prompt'])\n",
    "\n",
    "similarities = cosine_similarity(tfidf_test, tfidf_train)\n",
    "top_indices = np.argmax(similarities, axis=1)\n",
    "\n",
    "retrieved_responses = combined_data.iloc[top_indices]['conversation_id'].values\n",
    "\n",
    "answers=pd.DataFrame({})\n",
    "answers['conversation_id']=test_prompts['conversation_id']\n",
    "answers['response_id']=retrieved_responses\n",
    "\n",
    "answers.reset_index(drop=True, inplace=True)\n",
    "# print(answers.head(15))\n",
    "answers.to_csv('track_1_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238811b8-d2b8-4501-9aa7-5604d8f80efa",
   "metadata": {},
   "source": [
    "## Track II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5296fc70-b066-47e0-898e-dbbf7672aef3",
   "metadata": {},
   "source": [
    "This code use word embeddings and cosine similarity. After loading the data, they are lighly preprocessed, as in the previous track. It is then load the pre-trained word2vec-google-news-300 model and defines a function to compute sentence embeddings by averaging word vectors. The previous model was selected for its performance with respect to the BLEU score. The processed test prompts are converted into embeddings, and the cosine similarity is computed to find the closest match. The most similar is then selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdf870f6-98ee-49c1-b656-593edac6383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = load_data()\n",
    "test_prompts=pd.read_csv('test_prompts.csv')\n",
    "\n",
    "combined_data['user_prompt'] = combined_data['user_prompt'].astype(str)\n",
    "combined_data['model_response'] = combined_data['model_response'].astype(str)\n",
    "\n",
    "combined_data['processed_prompt'] = combined_data['user_prompt'].apply(preprocess_text)\n",
    "test_prompts['processed_prompt'] = test_prompts['user_prompt'].apply(preprocess_text)\n",
    "\n",
    "text_model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "def get_embedding(prompt, model):\n",
    "    words = prompt.split()\n",
    "    valid_vectors = [model[tok] for tok in words if tok in model.key_to_index]\n",
    "    return np.mean(valid_vectors, axis=0) if valid_vectors else np.zeros(model.vector_size)\n",
    "\n",
    "train_embeddings = np.vstack([get_embedding(prompt, text_model) for prompt in combined_data['processed_prompt']])\n",
    "test_embeddings = np.vstack([get_embedding(prompt, text_model) for prompt in test_prompts['processed_prompt']])\n",
    "\n",
    "similarities = cosine_similarity(test_embeddings, train_embeddings)\n",
    "\n",
    "top_indices = np.argmax(similarities, axis=1)\n",
    "retrieved_responses = combined_data.iloc[top_indices]['conversation_id'].values\n",
    "\n",
    "answers=pd.DataFrame({})\n",
    "answers['conversation_id']=test_prompts['conversation_id']\n",
    "answers['response_id']=retrieved_responses\n",
    "\n",
    "answers.reset_index(drop=True, inplace=True)\n",
    "# print(answers.head(15))\n",
    "answers.to_csv('track_2_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fe1a2-2f79-48ab-8519-6ae745b040c8",
   "metadata": {},
   "source": [
    "## Track III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc3c8e1-829d-4f24-9fdf-03462c58004a",
   "metadata": {},
   "source": [
    "This code combines semantic and lexical similarities. After loading and preprocessing the data, user prompts are encoded using the pre-trained BERT-based model 'all-mpnet-base-v2' (SentenceTransformer) to generate semantic embeddings. Although slower, this model provides higher-quality results, than for instance 'all-MiniLM-L12-v2'. Lexical similarities are computed using TF-IDF vectorization with word and character n-grams, as in track I. Both semantic and lexical similarities are combined with a weighted average (alpha=0.6), chosen based on its optimal BLEU score. This hybrid approach improves the accuracy of identifying the most relevant response by leveraging both semantic and lexical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49f3bcf-3948-4460-be83-fc2442fccbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = load_data()\n",
    "test_prompts=pd.read_csv('test_prompts.csv')\n",
    "\n",
    "combined_data['user_prompt'] = combined_data['user_prompt'].astype(str)\n",
    "combined_data['model_response'] = combined_data['model_response'].astype(str)\n",
    "\n",
    "combined_data['processed_prompt'] = combined_data['user_prompt'].apply(preprocess_text)\n",
    "test_prompts['processed_prompt'] = test_prompts['user_prompt'].apply(preprocess_text)\n",
    "\n",
    "bert_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "train_embeddings = bert_model.encode(combined_data['processed_prompt'].tolist(), convert_to_tensor=True)\n",
    "test_embeddings = bert_model.encode(test_prompts['processed_prompt'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "similarities = cosine_similarity(test_embeddings.cpu().numpy(), train_embeddings.cpu().numpy())\n",
    "\n",
    "ngram_range_w = (1, 2)\n",
    "ngram_range_c = (2, 4)\n",
    "max_df = 0.80\n",
    "min_df = 1\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(ngram_range=ngram_range_w, max_df=max_df, min_df=min_df, analyzer='word', sublinear_tf=True)\n",
    "char_vectorizer = TfidfVectorizer(ngram_range=ngram_range_c, max_df=max_df, min_df=min_df, analyzer='char', sublinear_tf=True)\n",
    "vectorizer = FeatureUnion([(\"word_tfidf\", word_vectorizer), (\"char_tfidf\", char_vectorizer)])\n",
    "\n",
    "train_tfidf = vectorizer.fit_transform(combined_data['processed_prompt'])\n",
    "test_tfidf = vectorizer.transform(test_prompts['processed_prompt'])\n",
    "lexical_similarities = cosine_similarity(test_tfidf, train_tfidf)\n",
    "\n",
    "alpha=0.6\n",
    "combined_similarities = alpha * similarities + (1 - alpha) * lexical_similarities\n",
    "top_indices = np.argmax(combined_similarities, axis=1)\n",
    "retrieved_responses = combined_data.iloc[top_indices]['conversation_id'].values\n",
    "\n",
    "answers=pd.DataFrame({})\n",
    "answers['conversation_id']=test_prompts['conversation_id']\n",
    "answers['response_id']=retrieved_responses\n",
    "\n",
    "answers.reset_index(drop=True, inplace=True)\n",
    "# print(answers.head(15))\n",
    "answers.to_csv('track_3_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
